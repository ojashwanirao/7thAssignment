{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6602f920-7e5c-42a0-8f96-c736275b4dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.\n",
    "#Multithreading:\n",
    "#i) I/O-bound Operations: When tasks involve significant waiting for I/O operations (like file reading/writing, network requests, or database queries), multithreading can be beneficial. In such cases, while one thread waits for I/O, other threads can continue executing, making better use of CPU time. Examples include web servers handling multiple requests simultaneously or applications that perform background file downloads while continuing to respond to user input.\n",
    "#ii) Lower Memory Usage: Since threads share the same memory space, multithreading is more memory-efficient compared to multiprocessing, where each process has its own memory space. This is advantageous in applications where memory resources are limited.\n",
    "#iii) Real-time Applications: In applications where tasks need to be executed concurrently with minimal latency, such as GUI applications where the interface must remain responsive, multithreading allows tasks to run simultaneously without blocking the main thread.\n",
    "\n",
    "#Multiprocessing:\n",
    "#i) CPU-bound Operations: For tasks that require heavy computation, like processing large datasets, performing complex mathematical calculations, or rendering graphics, multiprocessing is ideal. Since each process runs independently on its own CPU core, it avoids the Global Interpreter Lock (GIL) in Python, leading to true parallelism and improved performance.\n",
    "#ii) Isolation and Fault Tolerance: Each process in multiprocessing runs in its own memory space, which means that a crash in one process doesn't affect others. This isolation is beneficial in applications where reliability and fault tolerance are critical, such as in server applications or scientific computing.\n",
    "#iii) Scalability: In distributed systems, where tasks are spread across multiple machines, multiprocessing can be more easily scaled. Each process can be distributed across different nodes in a cluster, making it possible to handle massive workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c883510b-412f-483c-ae11-1aeb288b7bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Describe what a process pool is and how it helps in managing multiple processes efficiently. \n",
    "#A process pool is a programming abstraction provided by Python's multiprocessing module that manages a pool of worker processes to execute tasks concurrently. It allows developers to parallelize execution across multiple CPU cores without manually managing the creation, synchronization, and termination of processes.\n",
    "\n",
    "#How it Works:\n",
    "#i) Task Distribution: When a task is submitted to the process pool, it is automatically assigned to one of the available worker processes. This distribution is managed by the pool, which ensures that the workload is balanced across all available CPU cores.\n",
    "#ii) Resource Reuse: The process pool reuses existing processes to handle multiple tasks, reducing the overhead associated with creating and destroying processes. This leads to more efficient use of system resources, especially when dealing with a large number of small tasks.\n",
    "#iii) Simplified Interface: The process pool provides a simple and user-friendly interface for parallel execution. Functions like pool.map() and pool.apply_async() allow developers to easily distribute tasks across processes and collect results without needing to manage inter-process communication or synchronization explicitly.\n",
    "\n",
    "#Efficiency:\n",
    "#i) Reduced Overhead: By reusing processes and managing the distribution of tasks internally, a process pool reduces the overhead of process creation and termination, which can be significant in high-performance applications.\n",
    "#ii) Parallelism: Process pools enable true parallelism, leveraging multiple CPU cores to speed up execution. This is particularly beneficial for CPU-bound tasks where concurrency can significantly reduce processing time.\n",
    "\n",
    "#In summary, a process pool is a powerful tool for efficiently managing multiple processes, making it easier to write scalable, parallel programs in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6aa334c-80a1-47be-bcba-5f5245ea6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Explain what multiprocessing is and why it is used in Python programs.\n",
    "#Multiprocessing is a technique that involves running multiple processes concurrently, each with its own Python interpreter and memory space. Unlike multithreading, where threads share the same memory space and are subject to the Global Interpreter Lock (GIL), multiprocessing bypasses the GIL by using separate memory spaces for each process, allowing for true parallel execution on multi-core processors.\n",
    "\n",
    "#Why It is Used in Python:\n",
    "#i) Overcoming the GIL: Python's GIL prevents multiple native threads from executing Python bytecodes at once, which can be a bottleneck for CPU-bound tasks. Multiprocessing circumvents this limitation by running each process in its own Python interpreter, allowing multiple processes to execute simultaneously on different CPU cores.\n",
    "#ii) Parallelism for CPU-bound Tasks: For tasks that require significant computational power, such as image processing, numerical simulations, or data analysis, multiprocessing can significantly reduce execution time by utilizing all available CPU cores. This leads to improved performance, especially on multi-core machines.\n",
    "#iii) Isolation: Each process in a multiprocessing environment runs independently with its own memory space. This isolation means that the failure or crash of one process does not affect others, enhancing the robustness and stability of the application.\n",
    "#Scalability: Multiprocessing allows applications to scale across multiple cores or even multiple machines in a distributed system. This makes it suitable for large-scale computations and high-performance computing tasks where workload distribution is key to efficiency.\n",
    "\n",
    "#In essence, multiprocessing is used in Python to achieve true parallelism, optimize the performance of CPU-bound tasks, and build scalable, robust applications that can take full advantage of modern multi-core processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d9f58aa-f848-4582-a612-a496808f9d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 0: [0]\n",
      "Added 1: [0, 1]\n",
      "Added 2: [0, 1, 2]\n",
      "Added 3: [0, 1, 2, 3]\n",
      "Added 4: [0, 1, 2, 3, 4]\n",
      "Removed 0: [1, 2, 3, 4]\n",
      "Removed 1: [2, 3, 4]\n",
      "Removed 2: [3, 4]\n",
      "Removed 3: [4]\n",
      "Removed 4: []\n"
     ]
    }
   ],
   "source": [
    "#4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock.\n",
    "import threading\n",
    "\n",
    "class SharedList:\n",
    "    def __init__(self):\n",
    "        self.list = []\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def add_number(self, num):\n",
    "        with self.lock:\n",
    "            self.list.append(num)\n",
    "            print(f\"Added {num}: {self.list}\")\n",
    "\n",
    "    def remove_number(self):\n",
    "        with self.lock:\n",
    "            if self.list:\n",
    "                removed = self.list.pop(0)\n",
    "                print(f\"Removed {removed}: {self.list}\")\n",
    "\n",
    "def adder(shared_list):\n",
    "    for i in range(5):\n",
    "        shared_list.add_number(i)\n",
    "\n",
    "def remover(shared_list):\n",
    "    for _ in range(5):\n",
    "        shared_list.remove_number()\n",
    "\n",
    "shared_list = SharedList()\n",
    "thread1 = threading.Thread(target=adder, args=(shared_list,))\n",
    "thread2 = threading.Thread(target=remover, args=(shared_list,))\n",
    "\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "thread1.join()\n",
    "thread2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df3c4aa-8d08-417b-b7c3-cd0e83beb560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Describe the methods and tools available in Python for safely sharing data between threads and processes.\n",
    "#For Threads:\n",
    "#i) threading.Lock: This is a basic locking mechanism to ensure that only one thread can access a shared resource at a time. By using threading.Lock, you can prevent race conditions, where multiple threads try to modify shared data simultaneously, leading to unpredictable results.\n",
    "#ii) threading.RLock: This is a reentrant lock that allows a thread to acquire the same lock multiple times without causing a deadlock. It is useful when a thread needs to re-enter a critical section of code that it already holds the lock for.\n",
    "#iii) threading.Event: This synchronization primitive is used to communicate between threads. An Event can be set by one thread to signal one or more waiting threads to continue execution. This is useful for coordinating the execution flow of multiple threads.\n",
    "#iv) queue.Queue: This is a thread-safe FIFO queue that allows safe communication between threads. The queue.Queue class provides built-in locking to ensure that operations like putting and getting items are atomic and thread-safe.\n",
    "\n",
    "#For Processes:\n",
    "#i) multiprocessing.Queue: Similar to queue.Queue, but designed for inter-process communication. It allows safe data sharing between processes, ensuring that data passed between processes is serialized (using pickle) and transferred safely.\n",
    "#ii) multiprocessing.Manager: This provides a way to create shared objects (like lists, dictionaries, and namespaces) that can be safely accessed and modified by multiple processes. The Manager handles the synchronization and ensures that data integrity is maintained.\n",
    "#iii) multiprocessing.Value and Array: These are shared memory constructs that allow processes to share data like integers, floats, or arrays. The Value and Array classes provide synchronization through locks, ensuring that data is not corrupted by concurrent access.\n",
    "#iv) Shared Memory: Python 3.8 introduced the multiprocessing.shared_memory module, which allows processes to share large amounts of data in memory without copying it. This can lead to significant performance improvements in memory-intensive applications.\n",
    "\n",
    "#These tools and methods are essential for writing concurrent programs in Python, ensuring that data shared between threads or processes remains consistent, safe, and free from race conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "417914c6-e4a0-4eca-8595-52ad3ceb3f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing critical code\n",
      "Handled exception: An error occurred in the task\n",
      "Executing critical code\n",
      "Worker is running\n",
      "Worker is running\n",
      "Worker is running\n",
      "Worker is running\n",
      "Worker is running\n",
      "Worker stopped gracefully\n",
      "Main thread finished\n"
     ]
    }
   ],
   "source": [
    "#6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so.\n",
    "#Handling exceptions in concurrent programs is crucial because concurrent environments often involve complex interactions between multiple threads or processes. If exceptions are not properly handled, they can lead to unpredictable behavior, resource leaks, deadlocks, or crashes that are difficult to debug.\n",
    "\n",
    "#Why It’s Crucial:\n",
    "#i) Unpredictable State: In a concurrent environment, an unhandled exception in one thread or process can leave shared resources in an inconsistent or corrupted state. This can lead to cascading failures in other threads or processes that depend on those resources.\n",
    "#ii) Resource Leaks: If an exception occurs and is not properly handled, resources such as file handles, database connections, or memory may not be released, leading to resource leaks and eventually exhausting system resources.\n",
    "#iii) Deadlocks and Livelocks: Improper handling of exceptions can cause threads or processes to become stuck in a deadlock or livelock, where they wait indefinitely for a resource that will never become available.\n",
    "#iv) Crash of the Entire Application: In some cases, an unhandled exception in a critical thread or process can cause the entire application to crash, leading to loss of data and requiring a restart.\n",
    "\n",
    "#Techniques for Handling Exceptions:\n",
    "#i) Try-Except Blocks: Wrap critical sections of code in try-except blocks to catch and handle exceptions. This prevents exceptions from propagating and causing crashes.\n",
    "try:\n",
    "    # Critical code\n",
    "    print(\"Executing critical code\")\n",
    "except Exception as e:\n",
    "    # Handle exception\n",
    "    print(f\"Exception occurred: {e}\")\n",
    "\n",
    "#ii) Thread/Process Monitoring: Regularly monitor the status of threads and processes. Use mechanisms like concurrent.futures to handle exceptions raised in threads or processes, as it provides a way to capture and respond to exceptions.\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def task():\n",
    "    # Simulate a task that raises an exception\n",
    "    raise Exception(\"An error occurred in the task\")\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future = executor.submit(task)\n",
    "    try:\n",
    "        result = future.result()  # This will raise the exception from the task\n",
    "    except Exception as e:\n",
    "        print(f\"Handled exception: {e}\")\n",
    "\n",
    "#iii) Logging: Use logging to capture and record exceptions. This allows you to keep track of errors and diagnose issues without halting the entire application.\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "try:\n",
    "    # Critical code\n",
    "    print(\"Executing critical code\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Exception occurred: {e}\")\n",
    "\n",
    "#iv) Graceful Shutdown: Ensure that your concurrent program can shut down.\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Flag to control the thread execution\n",
    "stop_event = threading.Event()\n",
    "\n",
    "def worker():\n",
    "    while not stop_event.is_set():\n",
    "        # Simulate work\n",
    "        time.sleep(1)\n",
    "        print(\"Worker is running\")\n",
    "    print(\"Worker stopped gracefully\")\n",
    "\n",
    "# Start worker thread\n",
    "thread = threading.Thread(target=worker)\n",
    "thread.start()\n",
    "\n",
    "# Allow the worker thread to run for a while\n",
    "time.sleep(5)\n",
    "\n",
    "# Signal the worker thread to stop\n",
    "stop_event.set()\n",
    "\n",
    "# Wait for the worker thread to finish\n",
    "thread.join()\n",
    "print(\"Main thread finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c22ad3-534e-4161-951c-cbc266caa9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorials: [1, 2, 6, 24, 120, 720, 5040, 40320, 362880, 3628800]\n"
     ]
    }
   ],
   "source": [
    "#7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
    "import concurrent.futures\n",
    "import math\n",
    "\n",
    "def factorial(n):\n",
    "    return math.factorial(n)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    results = list(executor.map(factorial, range(1, 11)))\n",
    "\n",
    "print(\"Factorials:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d782e5b1-05f1-442e-9643-9aa41decd251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool Size 2: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] (Time: 0.0014 seconds)\n",
      "Pool Size 4: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] (Time: 0.0013 seconds)\n",
      "Pool Size 8: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] (Time: 0.0017 seconds)\n"
     ]
    }
   ],
   "source": [
    "#8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes).\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def square(n):\n",
    "    return n * n\n",
    "\n",
    "def measure_time(pool_size):\n",
    "    with multiprocessing.Pool(pool_size) as pool:\n",
    "        start_time = time.time()\n",
    "        results = pool.map(square, range(1, 11))\n",
    "        end_time = time.time()\n",
    "        print(f\"Pool Size {pool_size}: {results} (Time: {end_time - start_time:.4f} seconds)\")\n",
    "\n",
    "for size in [2, 4, 8]:\n",
    "    measure_time(size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
